"""
Objects Segmentator:
- Grounding DINO: detekuje objekty podle textov√©ho dotazu (open-vocabulary detection)
- SAM 2: z detekovan√Ωch box≈Ø udƒõl√° p≈ôesn√© masky (instance segmentation)
- Aplikace:
  - upload obr√°zku
  - zad√°n√≠ textu "co hled√°m" (nap≈ô. "person" / "car" / "dog" / "bottle")
  - nastaven√≠ prah≈Ø citlivosti
  - v√Ωstup: poƒçet instanc√≠ + instance overlay + union overlay + tabulka
"""

import io
from dataclasses import dataclass
from typing import List, Tuple, Dict, Any, Optional

import numpy as np
import streamlit as st
from PIL import Image, ImageDraw, ImageFont

import torch
from transformers import (
    AutoProcessor,
    AutoModelForZeroShotObjectDetection,
    Sam2Processor,
    Sam2Model,
)

# ----------------------------
# Datov√° struktura pro jednu nalezenou instanci
# ----------------------------
@dataclass
class Instance:
    """
    Reprezentuje 1 konkr√©tn√≠ nalezen√Ω objekt (1 instanci):
    - idx: po≈ôadov√© ƒç√≠slo (kv≈Øli popisk≈Øm v obr√°zku a tabulce)
    - label: textov√Ω label (podle dotazu/label≈Ø)
    - score: confidence z detektoru (GroundingDINO)
    - box_xyxy: bounding box v pixelech (x1,y1,x2,y2)
    - mask: bin√°rn√≠ maska HxW (True = pixel pat≈ô√≠ objektu)
    - area_px: plocha masky v pixelech (pro tabulku)
    """
    idx: int
    label: str
    score: float
    box_xyxy: Tuple[float, float, float, float]
    mask: np.ndarray  # HxW bool
    area_px: int


# ----------------------------
# Vizualizaƒçn√≠ pomocn√© funkce
# ----------------------------
def _safe_font(size: int = 16):
    """Fallback font."""
    for name in ["DejaVuSans.ttf", "Arial.ttf"]:
        try:
            return ImageFont.truetype(name, size=size)
        except Exception:
            pass
    return ImageFont.load_default()


def deterministic_color(i: int) -> Tuple[int, int, int]:
    """Deterministick√© v√Ωrazn√© barvy."""
    phi = 0.61803398875
    h = (i * phi) % 1.0
    s = 0.7
    v = 0.95
    k = int(h * 6)
    f = h * 6 - k
    p = int(255 * v * (1 - s))
    q = int(255 * v * (1 - f * s))
    t = int(255 * v * (1 - (1 - f) * s))
    V = int(255 * v)
    k = k % 6
    if k == 0:
        return (V, t, p)
    if k == 1:
        return (q, V, p)
    if k == 2:
        return (p, V, t)
    if k == 3:
        return (p, q, V)
    if k == 4:
        return (t, p, V)
    return (V, p, q)


def overlay_mask(base_rgb: np.ndarray, mask: np.ndarray, color: Tuple[int, int, int], alpha: float) -> np.ndarray:
    """P≈ôekreslen√≠ (overlay) masky p≈ôes obr√°zek."""
    out = base_rgb.astype(np.float32).copy()
    col = np.array(color, dtype=np.float32).reshape(1, 1, 3)
    out[mask] = out[mask] * (1 - alpha) + col * alpha
    return np.clip(out, 0, 255).astype(np.uint8)


def draw_boxes_and_ids(img: Image.Image, insts: List[Instance]) -> Image.Image:
    """Vykresl√≠ boxy + popisky (idx: label (score))."""
    out = img.copy()
    draw = ImageDraw.Draw(out)
    font = _safe_font(16)

    for ins in insts:
        x1, y1, x2, y2 = ins.box_xyxy
        draw.rectangle([x1, y1, x2, y2], outline=(255, 255, 255), width=2)

        txt = f"{ins.idx}: {ins.label} ({ins.score:.2f})"
        bbox = draw.textbbox((0, 0), txt, font=font)
        tw, th = bbox[2] - bbox[0], bbox[3] - bbox[1]
        y_top = max(0, y1 - th - 6)
        draw.rectangle([x1, y_top, x1 + tw + 8, y_top + th + 6], fill=(0, 0, 0))
        draw.text((x1 + 4, y_top + 3), txt, fill=(255, 255, 255), font=font)

    return out


def build_overlays(pil_img: Image.Image, insts: List[Instance], alpha: float, draw_boxes: bool):
    """
    Vytvo≈ô√≠ 2 vizualizace:
    - instance_overlay: ka≈æd√° instance jinou barvou (po instanc√≠ch)
    - union_overlay: v≈°echny instance dohromady (sjednocen√≠ masek)
    """
    base = np.array(pil_img.convert("RGB"))
    inst_overlay = base.copy()
    union_overlay = base.copy()

    if insts:
        # union maska = OR p≈ôes v≈°echny instanƒçn√≠ masky
        union_mask = np.zeros((base.shape[0], base.shape[1]), dtype=bool)
        for ins in insts:
            union_mask |= ins.mask

        # Zelen√Ω p≈ôekryv pro union
        union_overlay = overlay_mask(union_overlay, union_mask, (0, 255, 0), alpha)

        # Instance overlay = ka≈æd√° instance jinou barvou
        for i, ins in enumerate(insts, start=1):
            inst_overlay = overlay_mask(inst_overlay, ins.mask, deterministic_color(i), alpha)

    inst_img = Image.fromarray(inst_overlay)
    union_img = Image.fromarray(union_overlay)

    # Boxy + popisky
    if draw_boxes and insts:
        inst_img = draw_boxes_and_ids(inst_img, insts)
        union_img = draw_boxes_and_ids(union_img, insts)

    return inst_img, union_img


def table_rows(insts: List[Instance], img_size: Tuple[int, int]) -> List[Dict[str, Any]]:
    """Tabulka s metrikami instanc√≠."""
    W, H = img_size
    rows = []
    for ins in insts:
        x1, y1, x2, y2 = ins.box_xyxy
        rows.append(
            {
                "#": ins.idx,
                "label": ins.label,
                "score": round(ins.score, 4),
                "area_px": ins.area_px,
                "area_%": round(100.0 * ins.area_px / (W * H), 3),
                "box_xyxy": f"[{x1:.1f}, {y1:.1f}, {x2:.1f}, {y2:.1f}]",
            }
        )
    return rows


# ----------------------------
# Model loading (cache)
# ----------------------------
@st.cache_resource
def load_grounding_dino(model_id: str):
    """
    GroundingDINO:
    - AutoProcessor: p≈ôiprav√≠ vstup pro model (image + text)
    - AutoModelForZeroShotObjectDetection: open-vocabulary detekce box≈Ø
    """
    processor = AutoProcessor.from_pretrained(model_id)
    model = AutoModelForZeroShotObjectDetection.from_pretrained(model_id)
    model.eval()
    return processor, model


@st.cache_resource
def load_sam2(model_id: str):
    """
    SAM2 (Transformers):
    - Sam2Processor: p≈ôiprav√≠ prompt (box) + obraz pro segmentaci
    - Sam2Model: vrac√≠ masky (m≈Ø≈æe vracet v√≠ce kandid√°t≈Ø + iou_scores)
    """
    processor = Sam2Processor.from_pretrained(model_id)
    model = Sam2Model.from_pretrained(model_id)
    model.eval()
    return processor, model


# ----------------------------
# Core pipeline
# ----------------------------
def parse_labels(query: str) -> List[str]:
    """U≈æivatel m≈Ø≈æe napsat: 'person' nebo 'person, car'."""
    q = query.strip()
    if not q:
        return []
    parts = [p.strip() for p in q.replace(";", ",").split(",")]
    return [p for p in parts if p]


def run_pipeline(
        pil_img: Image.Image,
        text_query: str,
        box_threshold: float,
        text_threshold: float,
        max_det: int,
        sam_bin_thr: float,
        dino_processor,
        dino_model,
        sam_processor,
        sam_model,
        device: torch.device,
) -> List[Instance]:
    """
    Pipeline (Text ‚Üí boxy ‚Üí masky):
    1) GroundingDINO: najde bounding boxy v≈°ech objekt≈Ø odpov√≠daj√≠c√≠ch textu
    2) SAM2: pro ka≈æd√Ω box vytvo≈ô√≠ masku instance
    """

    labels = parse_labels(text_query)
    if not labels:
        return []

    # 1) GroundingDINO: image + labels -> boxy
    inputs = dino_processor(images=pil_img, text=[labels], return_tensors="pt").to(device)
    with torch.no_grad():
        outputs = dino_model(**inputs)

    # postprocess: vrac√≠ boxy v pixelech xyxy
    res = dino_processor.post_process_grounded_object_detection(
        outputs,
        inputs.input_ids,
        threshold=box_threshold,
        text_threshold=text_threshold,
        target_sizes=[pil_img.size[::-1]],  # (H, W)
    )[0]

    boxes = res.get("boxes", None)
    scores = res.get("scores", None)
    det_labels = res.get("labels", None)

    if boxes is None or len(boxes) == 0:
        return []

    # Nƒõkter√© verze processors mohou vracet list / numpy / tensor.
    # Pro stabilitu p≈ôevedeme v≈°e na numpy.
    def to_numpy(x):
        """P≈ôevede Tensor / numpy / list na numpy array."""
        if x is None:
            return None
        if isinstance(x, torch.Tensor):
            return x.detach().cpu().numpy()
        if isinstance(x, np.ndarray):
            return x
        return np.array(x)

    boxes = to_numpy(boxes)
    scores = to_numpy(scores)
    det_labels = to_numpy(det_labels)

    # kdyby labels chybƒõly, vytvo≈ô√≠me dummy indexy (pak se label_str jen defaultuje)
    if det_labels is None:
        det_labels = np.zeros(len(scores), dtype=int)

    # omez poƒçet detekc√≠ (kv≈Øli rychlosti a p≈ôehlednosti)
    order = np.argsort(-scores)[:max_det]
    boxes = boxes[order]
    scores = scores[order]
    det_labels = det_labels[order]

    # 2) SAM2: box -> maska
    sam_model = sam_model.to(device)
    raw = pil_img.convert("RGB")

    insts: List[Instance] = []
    with torch.no_grad():
        for i in range(len(boxes)):
            x1, y1, x2, y2 = boxes[i].tolist()
            score = float(scores[i])

            # mapov√°n√≠ label indexu na textov√Ω label
            label_str = labels[0] if len(labels) == 1 else text_query
            try:
                li = int(det_labels[i])
                if 0 <= li < len(labels):
                    label_str = labels[li]
            except Exception:
                pass

            # SAM2 dostane box jako prompt (v pixelech)
            sam_inputs = sam_processor(
                images=raw,
                input_boxes=[[[x1, y1, x2, y2]]],  # batch=1, num_boxes=1
                return_tensors="pt",
            ).to(device)

            sam_out = sam_model(**sam_inputs)

            # p≈ôe≈°k√°lov√°n√≠ masek na p≈Øvodn√≠ velikost obr√°zku
            masks = sam_processor.post_process_masks(
                sam_out.pred_masks.cpu(),
                sam_inputs["original_sizes"].cpu(),
            )[0]

            # masks: (1, K, H, W) nebo (K, H, W)
            if masks.ndim == 4:
                masks = masks[0]  # (K, H, W)

            # vyber nejlep≈°√≠ masku (pokud jsou iou_scores)
            best_k = 0
            if getattr(sam_out, "iou_scores", None) is not None:
                ious = sam_out.iou_scores.detach().cpu().numpy()
                ious = ious[0] if ious.ndim == 2 else ious
                best_k = int(np.argmax(ious))

            # binarizace masky
            mask = masks[best_k].numpy()
            mask_bool = mask > sam_bin_thr

            area = int(mask_bool.sum())
            if area == 0:
                continue

            insts.append(
                Instance(
                    idx=0,
                    label=label_str,
                    score=score,
                    box_xyxy=(x1, y1, x2, y2),
                    mask=mask_bool,
                    area_px=area,
                )
            )

    # se≈ôadit a oƒç√≠slovat
    insts.sort(key=lambda x: x.score, reverse=True)
    for j, ins in enumerate(insts, start=1):
        ins.idx = j
    return insts


# ----------------------------
# Streamlit GUI
# ----------------------------
st.set_page_config(page_title="Grounded SAM2: Text ‚Üí Segment ‚Üí Count", layout="wide")
st.title("Objects segmentator: Obr√°zek + Text ‚Üí najdi ‚Üí vysegmentuj ‚Üí spoƒç√≠tej")

st.write(
    "Nahraj obr√°zek, napi≈° co hled√°≈° (nap≈ô. **person**, **car**, **dog**, **bottle**) "
    "a aplikace najde v≈°echny objekty odpov√≠daj√≠c√≠ textu, vysegmentuje je a spoƒç√≠t√°."
)

with st.sidebar:
    st.header("Modely")

    dino_model_id = st.selectbox(
        "Grounding DINO",
        ["IDEA-Research/grounding-dino-tiny", "IDEA-Research/grounding-dino-base"],
        index=0,
        help="Tiny je rychlej≈°√≠, Base ƒçasto p≈ôesnƒõj≈°√≠.",
    )

    sam2_model_id = st.selectbox(
        "SAM2",
        [
            "facebook/sam2.1-hiera-base-plus",
            "facebook/sam2.1-hiera-small",
            "facebook/sam2.1-hiera-tiny",
            "facebook/sam2.1-hiera-large",
        ],
        index=0,
        help="Base-plus je dobr√Ω kompromis. Small/Tiny rychlej≈°√≠. Large nejkvalitnƒõj≈°√≠, ale tƒõ≈æ≈°√≠.",
    )

    st.divider()
    device_choice = st.radio("Za≈ô√≠zen√≠", ["Auto", "CPU", "GPU (CUDA)"], index=0)

    st.divider()
    st.subheader("Prahy (citlivost)")
    box_threshold = st.slider("Box threshold", 0.05, 0.95, 0.35, 0.05)
    text_threshold = st.slider("Text threshold", 0.05, 0.95, 0.25, 0.05)

    st.subheader("SAM2 maska")
    sam_bin_thr = st.slider("Binarizaƒçn√≠ pr√°h masky", 0.0, 1.0, 0.5, 0.05)

    st.divider()
    max_det = st.slider("Max. poƒçet instanc√≠", 1, 100, 25, 1)
    alpha = st.slider("Pr≈Øhlednost overlay", 0.10, 0.90, 0.45, 0.05)
    draw_boxes = st.checkbox("Zobrazit boxy + popisky", value=True)

# --- Vstupy od u≈æivatele (hlavn√≠ ƒç√°st UI) ---
uploaded = st.file_uploader("Obr√°zek (jpg/png)", type=["jpg", "jpeg", "png"])
text_query = st.text_input("Co hled√°m (text):", value="person")

if uploaded is None:
    st.info("Nahraj obr√°zek. Tip: bƒõ≈æn√© sc√©ny (lidi/auta/zv√≠≈ôata/p≈ôedmƒõty) funguj√≠ nejl√©pe.")
    st.stop()

# Naƒçten√≠ obr√°zku (PIL)
try:
    pil_img = Image.open(io.BytesIO(uploaded.read())).convert("RGB")
except Exception as e:
    st.error(f"Nelze naƒç√≠st obr√°zek: {e}")
    st.stop()

# V√Ωbƒõr za≈ô√≠zen√≠ (CPU/GPU)
if device_choice == "CPU":
    device = torch.device("cpu")
elif device_choice == "GPU (CUDA)":
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
else:
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Naƒçten√≠ model≈Ø (cache - naƒç√≠t√° se jen 1x, pak u≈æ je to rychl√©)
dino_processor, dino_model = load_grounding_dino(dino_model_id)
sam_processor, sam_model = load_sam2(sam2_model_id)
dino_model = dino_model.to(device)

# ----------------------------
# OVL√ÅD√ÅN√ç RERUN≈Æ: v√Ωpoƒçet a≈æ po kliknut√≠ na tlaƒç√≠tko
# ----------------------------
# Streamlit defaultnƒõ rerunuje skript po ka≈æd√© zmƒõnƒõ widgetu.
# Aby se inference nepou≈°tƒõla po≈ô√°d dokola, dr≈æ√≠me posledn√≠ v√Ωsledek v session_state
# a poƒç√≠t√°me jen na explicitn√≠ kliknut√≠.
if "last_result" not in st.session_state:
    st.session_state.last_result = None
if "last_meta" not in st.session_state:
    st.session_state.last_meta = None

col_run, col_clear = st.columns([1, 1])
with col_run:
    run_clicked = st.button("‚ñ∂ Spustit detekci + segmentaci", type="primary")
with col_clear:
    clear_clicked = st.button("üßπ Vymazat v√Ωsledek")

if clear_clicked:
    st.session_state.last_result = None
    st.session_state.last_meta = None
    st.rerun()

# Parametry bƒõhu ‚Äì ulo≈æ√≠me pro p≈ôehled (co p≈ôesnƒõ bylo nastaven√© p≈ôi aktu√°ln√≠m v√Ωpoƒçtu)
current_meta = {
    "text_query": text_query,
    "box_threshold": box_threshold,
    "text_threshold": text_threshold,
    "max_det": max_det,
    "sam_bin_thr": sam_bin_thr,
    "dino_model_id": dino_model_id,
    "sam2_model_id": sam2_model_id,
    "device": str(device),
}

if run_clicked:
    with st.spinner("Bƒõ≈æ√≠m: GroundingDINO (boxy) ‚Üí SAM2 (masky)‚Ä¶"):
        insts = run_pipeline(
            pil_img=pil_img,
            text_query=text_query,
            box_threshold=box_threshold,
            text_threshold=text_threshold,
            max_det=max_det,
            sam_bin_thr=sam_bin_thr,
            dino_processor=dino_processor,
            dino_model=dino_model,
            sam_processor=sam_processor,
            sam_model=sam_model,
            device=device,
        )
    st.session_state.last_result = insts
    st.session_state.last_meta = current_meta

# Pokud u≈æ m√°me v√Ωsledek z minul√©ho kliknut√≠, zobraz√≠me ho.
insts: Optional[List[Instance]] = st.session_state.last_result

if insts is None:
    st.info("Nastav parametry a klikni na **Spustit detekci + segmentaci**.")
    # Volitelnƒõ m≈Ø≈æe≈° zobrazit vstup i bez v√Ωsledku:
    st.image(pil_img, caption="Vstupn√≠ obr√°zek", use_container_width=True)
    st.stop()

# ----------------------------
# Zobrazen√≠ v√Ωsledk≈Ø
# ----------------------------
st.success(f"Nalezeno **{len(insts)}** instanc√≠ pro dotaz: **{st.session_state.last_meta['text_query']}**")

# Overlays: instance (po instanc√≠ch) + union (v≈°e dohromady)
inst_overlay, union_overlay = build_overlays(pil_img, insts, alpha=alpha, draw_boxes=draw_boxes)

c1, c2, c3 = st.columns([1, 1, 1])
with c1:
    st.subheader("Vstup")
    st.image(pil_img, use_container_width=True)
with c2:
    st.subheader("Ka≈æd√Ω objekt zvl√°≈°≈• (instance masky)")
    st.image(inst_overlay, use_container_width=True)
with c3:
    st.subheader("V≈°e dohromady (souhrnn√° maska)")
    st.image(union_overlay, use_container_width=True)

# Tabulka + tipy
st.subheader("Detaily detekc√≠")
if not insts:
    st.write("Nic nenalezeno. Zkus sn√≠≈æit box threshold nebo upravit text (nap≈ô. 'person' vs 'a person').")
else:
    st.dataframe(table_rows(insts, pil_img.size), use_container_width=True)

# Zobrazit meta parametry posledn√≠ho bƒõhu
with st.expander("Parametry posledn√≠ho bƒõhu (pro p≈ôehled / debug)"):
    st.json(st.session_state.last_meta)
